{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep MicroBiome\n",
    "\n",
    "Aug. 14. 2019\n",
    "@ Youngwon (youngwon08@gmail.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DATA/home/muha/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import keras.backend as k\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepbiome.deepbiome import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "k.set_session(tf.Session(config=config))\n",
    "\n",
    "logging.basicConfig(format = '[%(name)-8s|%(levelname)s|%(filename)s:%(lineno)s] %(message)s',\n",
    "                    level=logging.DEBUG)\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save = False\n",
    "# kfold=1000\n",
    "kfold=10\n",
    "network_model_keys = ['optimizer','lr','decay']\n",
    "architecture_keys = ['weight_decay', 'weight_l1_penalty', #'weight_l2_penalty',\n",
    "                     'tree_thrd', 'weight_initial',\n",
    "                     'batch_normalization','drop_out']\n",
    "network_training_keys = ['batch_size','epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# filenames = 'simulation_s0.Rmd'\n",
    "# models = [\n",
    "#           'simulation_s0/simulation_s0_deep',\n",
    "#           'simulation_s0/simulation_s0_deep_l1',\n",
    "#           'simulation_s0/simulation_s0_deepbiome',\n",
    "#          ]\n",
    "\n",
    "# models_aka = [\n",
    "#           'DNN',\n",
    "#           'DNN+l1',\n",
    "#           'DeepBiome',\n",
    "#          ]\n",
    "# num_classes = 0\n",
    "########################################################################\n",
    "# filenames = 'simulation_s1.Rmd'\n",
    "# models = [\n",
    "#           'simulation_s1/simulation_s1_deep',\n",
    "#           'simulation_s1/simulation_s1_deep_l1',\n",
    "#           'simulation_s1/simulation_s1_deepbiome',\n",
    "#          ]\n",
    "\n",
    "# models_aka = [\n",
    "#           'DNN',\n",
    "#           'DNN+l1',\n",
    "#           'DeepBiome',\n",
    "#          ]\n",
    "# num_classes = 0\n",
    "# ########################################################################\n",
    "filenames = 'simulation_s2_v1.Rmd'\n",
    "models = [\n",
    "          'simulation_s2/simulation_s2_deep',\n",
    "          'simulation_s2/simulation_s2_deep_l1',\n",
    "          'simulation_s2/simulation_s2_deepbiome',\n",
    "         ]\n",
    "\n",
    "models_aka = [\n",
    "          'DNN',\n",
    "          'DNN+l1',\n",
    "          'DeepBiome',\n",
    "         ]\n",
    "num_classes = 1\n",
    "# #######################################################################\n",
    "# filenames = 'simulation_s3.Rmd'\n",
    "# models = [\n",
    "#           'simulation_s3/simulation_s3_deep',\n",
    "#           'simulation_s3/simulation_s3_deep_l1',\n",
    "#           'simulation_s3/simulation_s3_deepbiome',\n",
    "#          ]\n",
    "\n",
    "# models_aka = [\n",
    "#           'DNN',\n",
    "#           'DNN+l1',\n",
    "#           'DeepBiome',\n",
    "#          ]\n",
    "# num_classes = 3\n",
    "# # ########################################################################\n",
    "# filenames = 'simulation_s4.Rmd'\n",
    "# models = [\n",
    "#           'simulation_s4/simulation_s4_deep',\n",
    "#           'simulation_s4/simulation_s4_deep_l1',\n",
    "#           'simulation_s4/simulation_s4_deepbiome',\n",
    "#          ]\n",
    "\n",
    "# models_aka = [\n",
    "#           'DNN',\n",
    "#           'DNN+l1',\n",
    "#           'DeepBiome',\n",
    "#          ]\n",
    "# num_classes = 0\n",
    "########################################################################\n",
    "# filenames = 'simulation_s5.Rmd'\n",
    "# models = [\n",
    "#           'simulation_s5/simulation_s4_deep',\n",
    "#           'simulation_s5/simulation_s4_deep_l1',\n",
    "#           'simulation_s5/simulation_s4_deepbiome',\n",
    "#          ]\n",
    "\n",
    "# models_aka = [\n",
    "#           'DNN',\n",
    "#           'DNN+l1',\n",
    "#           'DeepBiome',\n",
    "#          ]\n",
    "# num_classes = 0\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_network_info = {}\n",
    "model_path_info = {}\n",
    "for model_path in models:\n",
    "    config_data = configuration.Configurator('%s/config/path_info.cfg' % model_path, log, verbose=False)\n",
    "    config_data.set_config_map(config_data.get_section_map())\n",
    "    config_network = configuration.Configurator('%s/config/network_info.cfg' % model_path, log, verbose=False)\n",
    "    config_network.set_config_map(config_network.get_section_map())\n",
    "\n",
    "    model_path_info[model_path] = config_data.get_config_map()\n",
    "    model_network_info[model_path] = config_network.get_config_map()\n",
    "    \n",
    "if num_classes == 0: y_names = ['loss','correlation_coefficient']\n",
    "elif num_classes==1: y_names = ['loss','binary_accuracy','sensitivity','specificity','gmeasure', 'auc']\n",
    "else: y_names=['loss','categorical_accuracy','precision','recall','f1', 'auc']\n",
    "\n",
    "if num_classes == 0: measure_index = np.array([0,1])\n",
    "elif num_classes==1: measure_index = np.array([2,3,4,1,5])\n",
    "else: measure_index = np.array([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model & sensitivity & specificity & gmeasure & binary_accuracy & auc  \\\\\\ \\hline\n",
      "DNN &      0.916 &      0.031&     0.726 &      0.060&     0.814 &      0.033&     0.857 &      0.026&     0.916 &      0.026 &      0.974 &      0.016&     0.922 &      0.053&     0.948 &      0.033&     0.959 &      0.023&     0.981 &      0.014 \\\\\n",
      "DNN+l1 &      0.911 &      0.025&     0.772 &      0.042&     0.839 &      0.024&     0.868 &      0.021&     0.921 &      0.019 &      0.972 &      0.015&     0.952 &      0.019&     0.962 &      0.010&     0.966 &      0.010&     0.985 &      0.007 \\\\\n",
      "DeepBiome &      0.940 &      0.027&     0.862 &      0.053&     0.899 &      0.024&     0.915 &      0.017&     0.955 &      0.013 &      0.974 &      0.025&     0.960 &      0.031&     0.967 &      0.019&     0.970 &      0.019&     0.987 &      0.010 \\\\\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "# log.info('%20s & %s' % ('model', '& '.join(['%s ' % name for name in np.array(y_names)[[measure_index]]])))\n",
    "print('%20s & %s \\\\\\\\\\ \\hline' % ('model', '& '.join(['%s ' % name for name in np.array(y_names)[[measure_index]]])))\n",
    "# for model, aka in zip(models, models_aka):\n",
    "#     evaluation = np.load('%s/eval.npy' % model)\n",
    "#     log.info('%20s: %s' % (aka, ''.join(['%10.4f (%10.4f)'%(mean, std) for mean, std in zip(np.mean(evaluation, axis=0),np.std(evaluation, axis=0))])))\n",
    "#     results.append(np.vstack([np.mean(evaluation, axis=0),np.std(evaluation, axis=0)]).transpose())\n",
    "for model, aka in zip(models, models_aka):\n",
    "    train_evaluation = np.load('%s/train_eval.npy' % model)[:,measure_index]\n",
    "    train_res = '&'.join(['%10.3f & %10.3f'%(mean, std) for mean, std in zip(np.mean(train_evaluation, axis=0),np.std(train_evaluation, axis=0))])\n",
    "    test_evaluation = np.load('%s/test_eval.npy' % model)[:,measure_index]\n",
    "    test_res = '&'.join(['%10.3f & %10.3f'%(mean, std) for mean, std in zip(np.mean(test_evaluation, axis=0),np.std(test_evaluation, axis=0))])\n",
    "#     log.info('%s & %s & %s \\\\\\\\' % (aka, train_res, test_res))\n",
    "    print('%s & %s & %s \\\\\\\\' % (aka, test_res, train_res))\n",
    "#     results.append(np.vstack([np.mean(evaluation, axis=0),np.std(evaluation, axis=0)]).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=1\n",
    "model_path = models[num]\n",
    "model_aka = models_aka[num]\n",
    "\n",
    "config_data = configuration.Configurator('%s/config/path_info.cfg' % model_path, log, verbose=False)\n",
    "config_data.set_config_map(config_data.get_section_map())\n",
    "config_network = configuration.Configurator('%s/config/network_info.cfg' % model_path, log, verbose=False)\n",
    "config_network.set_config_map(config_network.get_section_map())\n",
    "\n",
    "path_info = config_data.get_config_map()\n",
    "network_info = config_network.get_config_map()\n",
    "\n",
    "path_info['data_info']['data_path'] = '/'.join(path_info['data_info']['data_path'].split('/')[2:])\n",
    "path_info['data_info']['tree_info_path'] = '/'.join(path_info['data_info']['tree_info_path'].split('/')[2:])\n",
    "try: path_info['data_info']['count_list_path'] = '/'.join(path_info['data_info']['count_list_path'].split('/')[2:])\n",
    "except: pass\n",
    "try: path_info['data_info']['count_path'] = '/'.join(path_info['data_info']['count_path'].split('/')[2:])\n",
    "except: pass\n",
    "path_info['data_info']['idx_path'] = '/'.join(path_info['data_info']['idx_path'].split('/')[2:])\n",
    "try: path_info['data_info']['disease_weight_path'] = '/'.join(path_info['data_info']['disease_weight_path'].split('/')[2:])\n",
    "except: pass\n",
    "\n",
    "log.info('%22s : %s' % ('model', model_path))\n",
    "log.info('%22s : %s' % ('model_aka', model_aka))\n",
    "for k in architecture_keys:\n",
    "    log.info('%22s : %s' % (k, network_info['architecture_info'].get(k, None)))\n",
    "for k in network_model_keys:\n",
    "    log.info('%22s : %s' % (k, network_info['model_info'].get(k, None)))\n",
    "for k in network_training_keys:\n",
    "    log.info('%22s : %s' % (k, network_info['training_info'].get(k, None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = np.load('%s/test_eval.npy' % model_path)\n",
    "log.info('\\t %s'%' '.join(['%s' % name for name in y_names]))\n",
    "\n",
    "_ = [log.info('%d fold : %s' % (i,line)) for i, line in enumerate(evaluation)]\n",
    "log.info('Mean   : %s' % np.mean(evaluation, axis=0))\n",
    "log.info('Std   : %s' % np.std(evaluation, axis=0))\n",
    "\n",
    "# _ = [print('%d fold & %s \\\\tabularnewline' % (i, ' & '.join(['%.3f'% v for v in line]))) for i, line in enumerate(evaluation)]\n",
    "# print('Mean & %s \\\\tabularnewline' % (' & '.join(['%.3f'% v for v in np.mean(evaluation, axis=0)])))\n",
    "# print('Sd & %s \\\\tabularnewline' % (' & '.join(['%.3f'% v for v in np.std(evaluation, axis=0)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight estimation of DeepBiom\n",
    "\n",
    "We identify the largest weight estimatio of neurons in two hidden layers; by doing this, we can identify the strongest phylogenetic connections. We compute the True Positive Rate (``TPR``, sensitivity), True Negative Rate (``TNR``, specificity), and their geometric mean (i.e., ``g-Measure``). The false discovery rate (FDR) would be ``FDR = 1-TPR`` in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def texa_selection_accuracy(tree_weight_list, true_tree_weight_list):\n",
    "    accuracy_list = []\n",
    "    for i in range(len(true_tree_weight_list)):\n",
    "        tree_tw = true_tree_weight_list[i].astype(np.int32)\n",
    "#         tree_tw = (true_tree_weight_list[i]>0).astype(np.int32)\n",
    "        tree_w = np.zeros_like(tree_tw, dtype=np.int32)\n",
    "        tree_w_abs = np.abs(tree_weight_list[i])\n",
    "        for row, maxcol in enumerate(np.argmax(tree_w_abs, axis=1)):\n",
    "            tree_w[row,maxcol] = tree_w_abs[row,maxcol]\n",
    "#         tree_w = (tree_w > 1e-2).astype(np.int32)\n",
    "        tree_w = (tree_w > 0).astype(np.int32)\n",
    "        num_selected_texa = np.sum(np.sum(tree_w, axis=1)>0)\n",
    "        sensitivity, specificity, gmeasure, accuracy = metric_texa_test(tree_tw.flatten(), tree_w.flatten())\n",
    "        accuracy_list.append([num_selected_texa, sensitivity, specificity, gmeasure, accuracy])\n",
    "    return accuracy_list\n",
    "\n",
    "def texa_selection_accuracy_2(tree_weight_list, true_tree_weight_list):\n",
    "    accuracy_list = []\n",
    "    for i in range(len(true_tree_weight_list)):\n",
    "        tree_tw = true_tree_weight_list[i].astype(np.int32)\n",
    "#         tree_tw = (true_tree_weight_list[i]>0).astype(np.int32)\n",
    "        tree_w = np.zeros_like(tree_tw, dtype=np.int32)\n",
    "        tree_w_abs = np.abs(tree_weight_list[i])\n",
    "        for row in range(tree_w_abs.shape[0]):\n",
    "#             tree_w[row,:] = (tree_w_abs[row,:]> 0).astype(np.int32)\n",
    "            tree_w[row,:] = (tree_w_abs[row,:]> 1e-2).astype(np.int32)\n",
    "        num_selected_texa = np.sum(np.sum(tree_w, axis=1)>0)\n",
    "        sensitivity, specificity, gmeasure, accuracy = metric_texa_test(tree_tw.flatten(), tree_w.flatten())\n",
    "        accuracy_list.append([num_selected_texa, sensitivity, specificity, gmeasure, accuracy])\n",
    "    return accuracy_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_weight_path = './%s/%s' % (model_path, path_info['model_info']['weight'])\n",
    "\n",
    "network_class = getattr(build_network, network_info['model_info']['network_class'].strip()) \n",
    "# network = network_class(network_info, path_info['data_info'], log, fold=0, num_classes=max(1,num_classes))\n",
    "network = network_class(network_info, path_info['data_info'], log, fold=0, num_classes=num_classes)\n",
    "network.model_compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "for fold in range(kfold):\n",
    "    network.fold = fold\n",
    "    network.load_weights(file_path_fold(model_weight_path, fold), verbose=False)\n",
    "    true_tree_weight_list = network.load_true_tree_weight_list(path_info['data_info']['data_path'])\n",
    "    tree_weight_list = network.get_trained_weight()\n",
    "    accuracy_list.append(np.array(texa_selection_accuracy(tree_weight_list, true_tree_weight_list)))\n",
    "accuracy_list = np.array(accuracy_list)[:,:,1:]\n",
    "\n",
    "# print('%7s, %12s, %12s, %12s, %12s, %12s, %12s' % ('Model','True (Total)','Selected','Sensitivity','Specificity','gMeasure','Accuracy'))\n",
    "# print('---------------------------------------------------------------------------------------------------------------')\n",
    "# values = []\n",
    "# for i, (mean, std) in enumerate(zip(np.mean(accuracy_list, axis=0), np.std(accuracy_list, axis=0))):\n",
    "#     tree_tw = true_tree_weight_list[i].astype(np.int32)\n",
    "#     args = [network.tree_level_list[i], np.sum(np.sum(tree_tw, axis=1)>0), tree_tw.shape[0]]+ np.stack([mean, std]).T.flatten().tolist()\n",
    "#     value = '%7s, %7d (%2d), %7d (%2d), %5.3f (%5.3f), %5.3f (%5.3f), %5.3f (%5.3f), %5.3f (%5.3f)' % tuple(args)\n",
    "#     values.append(value.split(','))\n",
    "    \n",
    "print('%7s, %12s, %12s, %12s, %12s, %12s, %12s' % ('Model','True (Total)','Selected','Sensitivity','Specificity','gMeasure','Accuracy'))\n",
    "print('---------------------------------------------------------------------------------------------------------------')\n",
    "values = []\n",
    "for i, (mean, std) in enumerate(zip(np.mean(accuracy_list, axis=0), np.std(accuracy_list, axis=0))):\n",
    "    tree_tw = true_tree_weight_list[i].astype(np.int32)\n",
    "    args = [network.tree_level_list[i], np.sum(np.sum(tree_tw, axis=1)>0), tree_tw.shape[0]]\n",
    "    value = '%7s & %7d (%2d)' % tuple(args)\n",
    "    value = '%s & %s \\\\\\\\' % (value, '&'.join(['%6.3f & %6.3f'%(m,s) for m, s in zip(mean, std)]))\n",
    "    if i == 0: print('%10s & %s' % (model_aka, value))\n",
    "    else: print('%10s & %s' % ('', value))\n",
    "    values.append(value.split(','))\n",
    "    \n",
    "# if save: \n",
    "#     # filenametexa = '.'.join([\"%s_select_texa_1\" % filename.split('.')[0], filename.split('.')[1]])\n",
    "#     colname = ['Tree','True (Total)','Selected','Sensitivity','Specificity','gMeasure','Accuracy']\n",
    "#     with open('%s/%s' % (analysis_dir, filename), mode='a') as f:\n",
    "#     #     f.write('---\\ntitle: \"%s texa selection ver.1\"\\noutput: html_document\\n---\\n\\n' % filename.split('.')[0])\n",
    "#         f.write('\\n## Texa Selection Preformance (ver 1): %s\\n\\n' % model_aka)\n",
    "#         f.write('| %s |\\n' % ('|'.join([v for v in colname])))\n",
    "#         f.write('|'+'---|'*len(colname)+'\\n')\n",
    "#         for value in values:\n",
    "#             f.write('| %s |\\n' % ('|'.join(value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "for fold in range(kfold):\n",
    "    network.fold = fold\n",
    "    network.load_weights(file_path_fold(model_weight_path, fold), verbose=False)\n",
    "    true_tree_weight_list = network.load_true_tree_weight_list(path_info['data_info']['data_path'])\n",
    "    tree_weight_list = network.get_trained_weight()\n",
    "    accuracy_list.append(np.array(texa_selection_accuracy(tree_weight_list, true_tree_weight_list)))\n",
    "accuracy_list = np.array(accuracy_list)[:,:,1:]\n",
    "\n",
    "# print('%7s, %12s, %12s, %12s, %12s, %12s, %12s' % ('Model','True (Total)','Selected','Sensitivity','Specificity','gMeasure','Accuracy'))\n",
    "# print('---------------------------------------------------------------------------------------------------------------')\n",
    "# values = []\n",
    "# for i, (mean, std) in enumerate(zip(np.mean(accuracy_list, axis=0), np.std(accuracy_list, axis=0))):\n",
    "#     tree_tw = true_tree_weight_list[i].astype(np.int32)\n",
    "#     args = [network.tree_level_list[i], np.sum(np.sum(tree_tw, axis=1)>0), tree_tw.shape[0]]+ np.stack([mean, std]).T.flatten().tolist()\n",
    "#     value = '%7s, %7d (%2d), %7d (%2d), %5.3f (%5.3f), %5.3f (%5.3f), %5.3f (%5.3f), %5.3f (%5.3f)' % tuple(args)\n",
    "#     values.append(value.split(','))\n",
    "    \n",
    "print('%7s, %12s, %12s, %12s, %12s, %12s, %12s' % ('Model','True (Total)','Selected','Sensitivity','Specificity','gMeasure','Accuracy'))\n",
    "print('---------------------------------------------------------------------------------------------------------------')\n",
    "values = []\n",
    "for i, (mean, std) in enumerate(zip(np.mean(accuracy_list, axis=0), np.std(accuracy_list, axis=0))):\n",
    "    tree_tw = true_tree_weight_list[i].astype(np.int32)\n",
    "    args = [network.tree_level_list[i], np.sum(np.sum(tree_tw, axis=1)>0), tree_tw.shape[0]]\n",
    "    value = '%7s & %7d (%2d)' % tuple(args)\n",
    "    value = '%s & %s \\\\\\\\' % (value, '&'.join(['%6.3f & %6.3f'%(m,s) for m, s in zip(mean, std)]))\n",
    "    if i == 0: print('%10s & %s' % (model_aka, value))\n",
    "    else: print('%10s & %s' % ('', value))\n",
    "    values.append(value.split(','))\n",
    "    \n",
    "# if save: \n",
    "#     # filenametexa = '.'.join([\"%s_select_texa_1\" % filename.split('.')[0], filename.split('.')[1]])\n",
    "#     colname = ['Tree','True (Total)','Selected','Sensitivity','Specificity','gMeasure','Accuracy']\n",
    "#     with open('%s/%s' % (analysis_dir, filename), mode='a') as f:\n",
    "#     #     f.write('---\\ntitle: \"%s texa selection ver.1\"\\noutput: html_document\\n---\\n\\n' % filename.split('.')[0])\n",
    "#         f.write('\\n## Texa Selection Preformance (ver 1): %s\\n\\n' % model_aka)\n",
    "#         f.write('| %s |\\n' % ('|'.join([v for v in colname])))\n",
    "#         f.write('|'+'---|'*len(colname)+'\\n')\n",
    "#         for value in values:\n",
    "#             f.write('| %s |\\n' % ('|'.join(value)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
