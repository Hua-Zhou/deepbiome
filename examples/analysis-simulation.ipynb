{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep MicroBiome\n",
    "\n",
    "Aug. 14. 2019\n",
    "@ Youngwon (youngwon08@gmail.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DATA/home/muha/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import keras.backend as k\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepbiome.deepbiome import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tf.__version__.startswith('2'): \n",
    "    config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "    k.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save = False\n",
    "# kfold=1000\n",
    "kfold=20\n",
    "network_model_keys = ['optimizer','lr','decay']\n",
    "architecture_keys = ['weight_decay', 'weight_l1_penalty', #'weight_l2_penalty',\n",
    "                     'tree_thrd', 'weight_initial',\n",
    "                     'batch_normalization','drop_out']\n",
    "network_training_keys = ['batch_size','epochs']\n",
    "\n",
    "logging.basicConfig(format = '[%(name)-8s|%(levelname)s|%(filename)s:%(lineno)s] %(message)s',\n",
    "                    level=logging.DEBUG)\n",
    "log = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# filenames = 'simulation_s0.Rmd'\n",
    "# models = [\n",
    "#           'simulation_s0/simulation_s0_deep',\n",
    "#           'simulation_s0/simulation_s0_deep_l1',\n",
    "#           'simulation_s0/simulation_s0_deepbiome',\n",
    "#          ]\n",
    "\n",
    "# models_aka = [\n",
    "#           'DNN',\n",
    "#           'DNN+l1',\n",
    "#           'DeepBiome',\n",
    "#          ]\n",
    "# num_classes = 0\n",
    "########################################################################\n",
    "# filenames = 'simulation_s1.Rmd'\n",
    "# models = [\n",
    "#           'simulation_s1/simulation_s1_deep',\n",
    "#           'simulation_s1/simulation_s1_deep_l1',\n",
    "#           'simulation_s1/simulation_s1_deepbiome',\n",
    "#          ]\n",
    "\n",
    "# models_aka = [\n",
    "#           'DNN',\n",
    "#           'DNN+l1',\n",
    "#           'DeepBiome',\n",
    "#          ]\n",
    "# num_classes = 0\n",
    "# ########################################################################\n",
    "# filenames = 'simulation_s2.Rmd'\n",
    "# models = [\n",
    "#           'simulation_s2/simulation_s2_deep',\n",
    "#           'simulation_s2/simulation_s2_deep_l1',\n",
    "#           'simulation_s2/simulation_s2_deepbiome',\n",
    "#          ]\n",
    "\n",
    "# models_aka = [\n",
    "#           'DNN',\n",
    "#           'DNN+l1',\n",
    "#           'DeepBiome',\n",
    "#          ]\n",
    "# num_classes = 1\n",
    "# #######################################################################\n",
    "# filenames = 'simulation_s3.Rmd'\n",
    "# models = [\n",
    "#           'simulation_s3/simulation_s3_deep',\n",
    "#           'simulation_s3/simulation_s3_deep_l1',\n",
    "#           'simulation_s3/simulation_s3_deepbiome',\n",
    "#          ]\n",
    "\n",
    "# models_aka = [\n",
    "#           'DNN',\n",
    "#           'DNN+l1',\n",
    "#           'DeepBiome',\n",
    "#          ]\n",
    "# num_classes = 3\n",
    "# # ########################################################################\n",
    "# filenames = 'simulation_s4.Rmd'\n",
    "# models = [\n",
    "#           'simulation_s4/simulation_s4_deep',\n",
    "#           'simulation_s4/simulation_s4_deep_l1',\n",
    "#           'simulation_s4/simulation_s4_deepbiome',\n",
    "#          ]\n",
    "\n",
    "# models_aka = [\n",
    "#           'DNN',\n",
    "#           'DNN+l1',\n",
    "#           'DeepBiome',\n",
    "#          ]\n",
    "# num_classes = 0\n",
    "########################################################################\n",
    "filenames = 'simulation_s5.Rmd'\n",
    "models = [\n",
    "          'simulation_s5/simulation_s5_deep',\n",
    "          'simulation_s5/simulation_s5_deep_l1',\n",
    "          'simulation_s5/simulation_s5_deepbiome',\n",
    "         ]\n",
    "\n",
    "models_aka = [\n",
    "          'DNN',\n",
    "          'DNN+l1',\n",
    "          'DeepBiome',\n",
    "         ]\n",
    "num_classes = 0\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_network_info = {}\n",
    "model_path_info = {}\n",
    "for model_path in models:\n",
    "    config_data = configuration.Configurator('%s/config/path_info.cfg' % model_path, log, verbose=False)\n",
    "    config_data.set_config_map(config_data.get_section_map())\n",
    "    config_network = configuration.Configurator('%s/config/network_info.cfg' % model_path, log, verbose=False)\n",
    "    config_network.set_config_map(config_network.get_section_map())\n",
    "\n",
    "    model_path_info[model_path] = config_data.get_config_map()\n",
    "    model_network_info[model_path] = config_network.get_config_map()\n",
    "    \n",
    "if num_classes == 0: y_names = ['loss','correlation_coefficient']\n",
    "elif num_classes==1: y_names = ['loss','binary_accuracy','sensitivity','specificity','gmeasure', 'auc']\n",
    "else: y_names=['loss','categorical_accuracy','precision','recall','f1', 'auc']\n",
    "\n",
    "if num_classes == 0: measure_index = np.array([0,1])\n",
    "elif num_classes==1: measure_index = np.array([2,3,4,1,5])\n",
    "else: measure_index = np.array([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     model &    loss &   (sd) & correlation_coefficient &   (sd)  \\\\\\ \\hline\n",
      "       DNN &   0.452 &   0.145&  0.842 &   0.058 &   0.166 &   0.154&  0.946 &   0.053 \\\\\n",
      "    DNN+l1 &   0.453 &   0.212&  0.843 &   0.075 &   0.173 &   0.165&  0.944 &   0.054 \\\\\n",
      " DeepBiome &   0.340 &   0.293&  0.885 &   0.096 &   0.207 &   0.215&  0.931 &   0.072 \\\\\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "# log.info('%20s & %s' % ('model', '& '.join(['%s ' % name for name in np.array(y_names)[[measure_index]]])))\n",
    "print('%10s & %s \\\\\\\\\\ \\hline' % ('model', '& '.join(['%7s &   (sd) ' % name for name in np.array(y_names)[[measure_index]]])))\n",
    "# for model, aka in zip(models, models_aka):\n",
    "#     evaluation = np.load('%s/eval.npy' % model)\n",
    "#     log.info('%20s: %s' % (aka, ''.join(['%10.4f (%10.4f)'%(mean, std) for mean, std in zip(np.mean(evaluation, axis=0),np.std(evaluation, axis=0))])))\n",
    "#     results.append(np.vstack([np.mean(evaluation, axis=0),np.std(evaluation, axis=0)]).transpose())\n",
    "for model, aka in zip(models, models_aka):\n",
    "    train_evaluation = np.load('%s/train_eval.npy' % model)[:,measure_index]\n",
    "    train_res = '&'.join(['%7.3f & %7.3f'%(mean, std) for mean, std in zip(np.mean(train_evaluation, axis=0),np.std(train_evaluation, axis=0))])\n",
    "    test_evaluation = np.load('%s/test_eval.npy' % model)[:,measure_index]\n",
    "    test_res = '&'.join(['%7.3f & %7.3f'%(mean, std) for mean, std in zip(np.mean(test_evaluation, axis=0),np.std(test_evaluation, axis=0))])\n",
    "#     log.info('%s & %s & %s \\\\\\\\' % (aka, train_res, test_res))\n",
    "    print('%10s & %s & %s \\\\\\\\' % (aka, test_res, train_res))\n",
    "#     results.append(np.vstack([np.mean(evaluation, axis=0),np.std(evaluation, axis=0)]).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|<ipython-input-8-ce0e784f4c7b>:23]                  model : simulation_s5/simulation_s5_deepbiome\n",
      "[root    |INFO|<ipython-input-8-ce0e784f4c7b>:24]              model_aka : DeepBiome\n",
      "[root    |INFO|<ipython-input-8-ce0e784f4c7b>:26]           weight_decay : phylogenetic_tree\n",
      "[root    |INFO|<ipython-input-8-ce0e784f4c7b>:26]      weight_l1_penalty : None\n",
      "[root    |INFO|<ipython-input-8-ce0e784f4c7b>:26]              tree_thrd : None\n",
      "[root    |INFO|<ipython-input-8-ce0e784f4c7b>:26]         weight_initial : glorot_uniform\n",
      "[root    |INFO|<ipython-input-8-ce0e784f4c7b>:26]    batch_normalization : False\n",
      "[root    |INFO|<ipython-input-8-ce0e784f4c7b>:26]               drop_out : 0\n",
      "[root    |INFO|<ipython-input-8-ce0e784f4c7b>:28]              optimizer : adam\n",
      "[root    |INFO|<ipython-input-8-ce0e784f4c7b>:28]                     lr : 0.01\n",
      "[root    |INFO|<ipython-input-8-ce0e784f4c7b>:28]                  decay : 0.0001\n",
      "[root    |INFO|<ipython-input-8-ce0e784f4c7b>:30]             batch_size : 100\n",
      "[root    |INFO|<ipython-input-8-ce0e784f4c7b>:30]                 epochs : 5000\n"
     ]
    }
   ],
   "source": [
    "num=2\n",
    "model_path = models[num]\n",
    "model_aka = models_aka[num]\n",
    "\n",
    "config_data = configuration.Configurator('%s/config/path_info.cfg' % model_path, log, verbose=False)\n",
    "config_data.set_config_map(config_data.get_section_map())\n",
    "config_network = configuration.Configurator('%s/config/network_info.cfg' % model_path, log, verbose=False)\n",
    "config_network.set_config_map(config_network.get_section_map())\n",
    "\n",
    "path_info = config_data.get_config_map()\n",
    "network_info = config_network.get_config_map()\n",
    "\n",
    "path_info['data_info']['data_path'] = '/'.join(path_info['data_info']['data_path'].split('/')[2:])\n",
    "path_info['data_info']['tree_info_path'] = '/'.join(path_info['data_info']['tree_info_path'].split('/')[2:])\n",
    "try: path_info['data_info']['count_list_path'] = '/'.join(path_info['data_info']['count_list_path'].split('/')[2:])\n",
    "except: pass\n",
    "try: path_info['data_info']['count_path'] = '/'.join(path_info['data_info']['count_path'].split('/')[2:])\n",
    "except: pass\n",
    "path_info['data_info']['idx_path'] = '/'.join(path_info['data_info']['idx_path'].split('/')[2:])\n",
    "try: path_info['data_info']['disease_weight_path'] = '/'.join(path_info['data_info']['disease_weight_path'].split('/')[2:])\n",
    "except: pass\n",
    "\n",
    "log.info('%22s : %s' % ('model', model_path))\n",
    "log.info('%22s : %s' % ('model_aka', model_aka))\n",
    "for k in architecture_keys:\n",
    "    log.info('%22s : %s' % (k, network_info['architecture_info'].get(k, None)))\n",
    "for k in network_model_keys:\n",
    "    log.info('%22s : %s' % (k, network_info['model_info'].get(k, None)))\n",
    "for k in network_training_keys:\n",
    "    log.info('%22s : %s' % (k, network_info['training_info'].get(k, None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:2] \t loss correlation_coefficient\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 0 fold : [0.16498545 0.95444393]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 1 fold : [0.40153968 0.85734338]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 2 fold : [0.18313099 0.93103552]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 3 fold : [0.54323459 0.69919032]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 4 fold : [0.04451896 0.98543644]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 5 fold : [0.10042844 0.96639681]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 6 fold : [0.50367033 0.80044782]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 7 fold : [0.78441083 0.76607352]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 8 fold : [1.11524379 0.6946708 ]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 9 fold : [0.57597065 0.81630051]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 10 fold : [0.36916009 0.89176601]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 11 fold : [0.52776217 0.8485775 ]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 12 fold : [0.00487854 0.99860531]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 13 fold : [0.50965679 0.8503359 ]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 14 fold : [0.31863484 0.88517243]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 15 fold : [0.51886284 0.80566752]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 16 fold : [0.0128353 0.9951725]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 17 fold : [0.00332941 0.9988066 ]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 18 fold : [0.02204559 0.99279767]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:4] 19 fold : [0.09656429 0.96451366]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:5] Mean   : [0.34004318 0.88513771]\n",
      "[root    |INFO|<ipython-input-9-65b4b58a34e1>:6] Std   : [0.29294965 0.09643347]\n"
     ]
    }
   ],
   "source": [
    "evaluation = np.load('%s/test_eval.npy' % model_path)\n",
    "log.info('\\t %s'%' '.join(['%s' % name for name in y_names]))\n",
    "\n",
    "_ = [log.info('%d fold : %s' % (i,line)) for i, line in enumerate(evaluation)]\n",
    "log.info('Mean   : %s' % np.mean(evaluation, axis=0))\n",
    "log.info('Std   : %s' % np.std(evaluation, axis=0))\n",
    "\n",
    "# _ = [print('%d fold & %s \\\\tabularnewline' % (i, ' & '.join(['%.3f'% v for v in line]))) for i, line in enumerate(evaluation)]\n",
    "# print('Mean & %s \\\\tabularnewline' % (' & '.join(['%.3f'% v for v in np.mean(evaluation, axis=0)])))\n",
    "# print('Sd & %s \\\\tabularnewline' % (' & '.join(['%.3f'% v for v in np.std(evaluation, axis=0)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight estimation of DeepBiom\n",
    "\n",
    "We identify the largest weight estimatio of neurons in two hidden layers; by doing this, we can identify the strongest phylogenetic connections. We compute the True Positive Rate (``TPR``, sensitivity), True Negative Rate (``TNR``, specificity), and their geometric mean (i.e., ``g-Measure``). The false discovery rate (FDR) would be ``FDR = 1-TPR`` in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def texa_selection_accuracy(tree_weight_list, true_tree_weight_list):\n",
    "    accuracy_list = []\n",
    "    for i in range(len(true_tree_weight_list)):\n",
    "        tree_tw = true_tree_weight_list[i].astype(np.int32)\n",
    "        tree_w = np.zeros_like(tree_tw, dtype=np.int32)\n",
    "        tree_w_abs = np.abs(tree_weight_list[i])\n",
    "        for row, maxcol in enumerate(np.argmax(tree_w_abs, axis=1)):\n",
    "            tree_w[row,maxcol] = tree_w_abs[row,maxcol]\n",
    "#         tree_w = (tree_w > 1e-2).astype(np.int32)\n",
    "        tree_w = (tree_w > 0).astype(np.int32)\n",
    "        num_selected_texa = np.sum(np.sum(tree_w, axis=1)>0)\n",
    "        sensitivity, specificity, gmeasure, accuracy = loss_and_metric.metric_texa_test(tree_tw.flatten(), tree_w.flatten())\n",
    "        accuracy_list.append([num_selected_texa, sensitivity, specificity, gmeasure, accuracy])\n",
    "    return accuracy_list\n",
    "\n",
    "def texa_selection_accuracy_2(tree_weight_list, true_tree_weight_list):\n",
    "    accuracy_list = []\n",
    "    for i in range(len(true_tree_weight_list)):\n",
    "        tree_tw = true_tree_weight_list[i].astype(np.int32)\n",
    "        tree_w = np.zeros_like(tree_tw, dtype=np.int32)\n",
    "        tree_w_abs = np.abs(tree_weight_list[i])\n",
    "#         tree_w = (tree_w_abs>1e-2).astype(np.int32)\n",
    "        for row in range(tree_w_abs.shape[0]):\n",
    "#             tree_w[row,:] = (tree_w_abs[row,:]> 0).astype(np.int32)\n",
    "            tree_w[row,:] = (tree_w_abs[row,:]> 1e-2).astype(np.int32)\n",
    "        num_selected_texa = np.sum(np.sum(tree_w, axis=1)>0)\n",
    "        sensitivity, specificity, gmeasure, accuracy = loss_and_metric.metric_texa_test(tree_tw.flatten(), tree_w.flatten())\n",
    "        accuracy_list.append([num_selected_texa, sensitivity, specificity, gmeasure, accuracy])\n",
    "    return accuracy_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[root    |INFO|build_network.py:508] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:509] Read phylogenetic tree information from data/genus48/genus48_dic_misspecify.csv\n",
      "[root    |INFO|build_network.py:513] Phylogenetic tree level list: ['Genus', 'Family', 'Order', 'Class', 'Phylum']\n",
      "[root    |INFO|build_network.py:514] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:521]      Genus: 48\n",
      "[root    |INFO|build_network.py:521]     Family: 40\n",
      "[root    |INFO|build_network.py:521]      Order: 23\n",
      "[root    |INFO|build_network.py:521]      Class: 17\n",
      "[root    |INFO|build_network.py:521]     Phylum: 9\n",
      "[root    |INFO|build_network.py:524] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:525] Phylogenetic_tree_dict info: ['Class', 'Phylum', 'Order', 'Genus', 'Family', 'Number']\n",
      "[root    |INFO|build_network.py:526] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:536] Build edge weights between [ Genus, Family]\n",
      "[root    |INFO|build_network.py:536] Build edge weights between [Family,  Order]\n",
      "[root    |INFO|build_network.py:536] Build edge weights between [ Order,  Class]\n",
      "[root    |INFO|build_network.py:536] Build edge weights between [ Class, Phylum]\n",
      "[root    |INFO|build_network.py:549] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:565] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:566] Build network based on phylogenetic tree information\n",
      "[root    |INFO|build_network.py:567] ------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:432: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tensorflow|WARNING|deprecation.py:328] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:432: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "[root    |INFO|build_network.py:643] ------------------------------------------------------------------------------------------\n",
      "[root    |INFO|build_network.py:57] Build Network\n",
      "[root    |INFO|build_network.py:58] Optimizer = adam\n",
      "[root    |INFO|build_network.py:59] Loss = mean_squared_error\n",
      "[root    |INFO|build_network.py:60] Metrics = correlation_coefficient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "l1_dense (Dense_with_tree)   (None, 40)                1960      \n",
      "_________________________________________________________________\n",
      "l1_activation (Activation)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "l2_dense (Dense_with_tree)   (None, 23)                943       \n",
      "_________________________________________________________________\n",
      "l2_activation (Activation)   (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "l3_dense (Dense_with_tree)   (None, 17)                408       \n",
      "_________________________________________________________________\n",
      "l3_activation (Activation)   (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "l4_dense (Dense_with_tree)   (None, 9)                 162       \n",
      "_________________________________________________________________\n",
      "l4_activation (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "last_dense_h (Dense)         (None, 1)                 10        \n",
      "_________________________________________________________________\n",
      "p_hat (Activation)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,483\n",
      "Trainable params: 3,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_weight_path = './%s/%s' % (model_path, path_info['model_info']['weight'])\n",
    "\n",
    "network_class = getattr(build_network, network_info['model_info']['network_class'].strip()) \n",
    "# network = network_class(network_info, path_info['data_info'], log, fold=0, num_classes=max(1,num_classes))\n",
    "network = network_class(network_info, path_info['data_info'], log, fold=0, num_classes=num_classes)\n",
    "network.model_compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model, True (Total),     Selected,  Sensitivity,  Specificity,     gMeasure,     Accuracy\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      " DeepBiome &   Genus &      19 (48) &  0.247 &  0.139& 0.997 &  0.002& 0.467 &  0.168& 0.990 &  0.002 \\\\\n",
      "           &  Family &      15 (40) &  0.240 &  0.167& 0.995 &  0.002& 0.444 &  0.204& 0.982 &  0.003 \\\\\n",
      "           &   Order &       4 (23) &  0.113 &  0.124& 0.994 &  0.004& 0.224 &  0.248& 0.985 &  0.005 \\\\\n",
      "           &   Class &       3 (17) &  0.067 &  0.133& 0.989 &  0.008& 0.115 &  0.231& 0.971 &  0.009 \\\\\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "for fold in range(kfold):\n",
    "    network.fold = fold\n",
    "    network.load_weights(file_path_fold(model_weight_path, fold), verbose=False)\n",
    "    true_tree_weight_list = network.load_true_tree_weight_list(path_info['data_info']['data_path'])\n",
    "    tree_weight_list = network.get_trained_weight()\n",
    "    accuracy_list.append(np.array(texa_selection_accuracy(tree_weight_list, true_tree_weight_list)))\n",
    "accuracy_list = np.array(accuracy_list)[:,:,1:]\n",
    "\n",
    "# print('%7s, %12s, %12s, %12s, %12s, %12s, %12s' % ('Model','True (Total)','Selected','Sensitivity','Specificity','gMeasure','Accuracy'))\n",
    "# print('---------------------------------------------------------------------------------------------------------------')\n",
    "# values = []\n",
    "# for i, (mean, std) in enumerate(zip(np.mean(accuracy_list, axis=0), np.std(accuracy_list, axis=0))):\n",
    "#     tree_tw = true_tree_weight_list[i].astype(np.int32)\n",
    "#     args = [network.tree_level_list[i], np.sum(np.sum(tree_tw, axis=1)>0), tree_tw.shape[0]]+ np.stack([mean, std]).T.flatten().tolist()\n",
    "#     value = '%7s, %7d (%2d), %7d (%2d), %5.3f (%5.3f), %5.3f (%5.3f), %5.3f (%5.3f), %5.3f (%5.3f)' % tuple(args)\n",
    "#     values.append(value.split(','))\n",
    "    \n",
    "print('%7s, %12s, %12s, %12s, %12s, %12s, %12s' % ('Model','True (Total)','Selected','Sensitivity','Specificity','gMeasure','Accuracy'))\n",
    "print('---------------------------------------------------------------------------------------------------------------')\n",
    "values = []\n",
    "for i, (mean, std) in enumerate(zip(np.mean(accuracy_list, axis=0), np.std(accuracy_list, axis=0))):\n",
    "    tree_tw = true_tree_weight_list[i].astype(np.int32)\n",
    "    args = [network.tree_level_list[i], np.sum(np.sum(tree_tw, axis=1)>0), tree_tw.shape[0]]\n",
    "    value = '%7s & %7d (%2d)' % tuple(args)\n",
    "    value = '%s & %s \\\\\\\\' % (value, '&'.join(['%6.3f & %6.3f'%(m,s) for m, s in zip(mean, std)]))\n",
    "    if i == 0: print('%10s & %s' % (model_aka, value))\n",
    "    else: print('%10s & %s' % ('', value))\n",
    "    values.append(value.split(','))\n",
    "    \n",
    "# if save: \n",
    "#     # filenametexa = '.'.join([\"%s_select_texa_1\" % filename.split('.')[0], filename.split('.')[1]])\n",
    "#     colname = ['Tree','True (Total)','Selected','Sensitivity','Specificity','gMeasure','Accuracy']\n",
    "#     with open('%s/%s' % (analysis_dir, filename), mode='a') as f:\n",
    "#     #     f.write('---\\ntitle: \"%s texa selection ver.1\"\\noutput: html_document\\n---\\n\\n' % filename.split('.')[0])\n",
    "#         f.write('\\n## Texa Selection Preformance (ver 1): %s\\n\\n' % model_aka)\n",
    "#         f.write('| %s |\\n' % ('|'.join([v for v in colname])))\n",
    "#         f.write('|'+'---|'*len(colname)+'\\n')\n",
    "#         for value in values:\n",
    "#             f.write('| %s |\\n' % ('|'.join(value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model, True (Total),     Selected,  Sensitivity,  Specificity,     gMeasure,     Accuracy\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      " DeepBiome &   Genus &      19 (48) &  0.929 &  0.056& 0.650 &  0.093& 0.775 &  0.058& 0.653 &  0.092 \\\\\n",
      "           &  Family &      15 (40) &  0.910 &  0.048& 0.800 &  0.065& 0.852 &  0.042& 0.802 &  0.064 \\\\\n",
      "           &   Order &       4 (23) &  0.550 &  0.170& 0.840 &  0.060& 0.668 &  0.102& 0.837 &  0.059 \\\\\n",
      "           &   Class &       3 (17) &  0.683 &  0.128& 0.821 &  0.051& 0.746 &  0.076& 0.819 &  0.050 \\\\\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "for fold in range(kfold):\n",
    "    network.fold = fold\n",
    "    network.load_weights(file_path_fold(model_weight_path, fold), verbose=False)\n",
    "    true_tree_weight_list = network.load_true_tree_weight_list(path_info['data_info']['data_path'])\n",
    "    tree_weight_list = network.get_trained_weight()\n",
    "    accuracy_list.append(np.array(texa_selection_accuracy_2(tree_weight_list, true_tree_weight_list)))\n",
    "accuracy_list = np.array(accuracy_list)[:,:,1:]\n",
    "\n",
    "# print('%7s, %12s, %12s, %12s, %12s, %12s, %12s' % ('Model','True (Total)','Selected','Sensitivity','Specificity','gMeasure','Accuracy'))\n",
    "# print('---------------------------------------------------------------------------------------------------------------')\n",
    "# values = []\n",
    "# for i, (mean, std) in enumerate(zip(np.mean(accuracy_list, axis=0), np.std(accuracy_list, axis=0))):\n",
    "#     tree_tw = true_tree_weight_list[i].astype(np.int32)\n",
    "#     args = [network.tree_level_list[i], np.sum(np.sum(tree_tw, axis=1)>0), tree_tw.shape[0]]+ np.stack([mean, std]).T.flatten().tolist()\n",
    "#     value = '%7s, %7d (%2d), %7d (%2d), %5.3f (%5.3f), %5.3f (%5.3f), %5.3f (%5.3f), %5.3f (%5.3f)' % tuple(args)\n",
    "#     values.append(value.split(','))\n",
    "    \n",
    "print('%7s, %12s, %12s, %12s, %12s, %12s, %12s' % ('Model','True (Total)','Selected','Sensitivity','Specificity','gMeasure','Accuracy'))\n",
    "print('---------------------------------------------------------------------------------------------------------------')\n",
    "values = []\n",
    "for i, (mean, std) in enumerate(zip(np.mean(accuracy_list, axis=0), np.std(accuracy_list, axis=0))):\n",
    "    tree_tw = true_tree_weight_list[i].astype(np.int32)\n",
    "    args = [network.tree_level_list[i], np.sum(np.sum(tree_tw, axis=1)>0), tree_tw.shape[0]]\n",
    "    value = '%7s & %7d (%2d)' % tuple(args)\n",
    "    value = '%s & %s \\\\\\\\' % (value, '&'.join(['%6.3f & %6.3f'%(m,s) for m, s in zip(mean, std)]))\n",
    "    if i == 0: print('%10s & %s' % (model_aka, value))\n",
    "    else: print('%10s & %s' % ('', value))\n",
    "    values.append(value.split(','))\n",
    "    \n",
    "# if save: \n",
    "#     # filenametexa = '.'.join([\"%s_select_texa_1\" % filename.split('.')[0], filename.split('.')[1]])\n",
    "#     colname = ['Tree','True (Total)','Selected','Sensitivity','Specificity','gMeasure','Accuracy']\n",
    "#     with open('%s/%s' % (analysis_dir, filename), mode='a') as f:\n",
    "#     #     f.write('---\\ntitle: \"%s texa selection ver.1\"\\noutput: html_document\\n---\\n\\n' % filename.split('.')[0])\n",
    "#         f.write('\\n## Texa Selection Preformance (ver 1): %s\\n\\n' % model_aka)\n",
    "#         f.write('| %s |\\n' % ('|'.join([v for v in colname])))\n",
    "#         f.write('|'+'---|'*len(colname)+'\\n')\n",
    "#         for value in values:\n",
    "#             f.write('| %s |\\n' % ('|'.join(value)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
